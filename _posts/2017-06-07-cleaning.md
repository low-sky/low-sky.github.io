---
layout: post
title: Adventures in Cleaning
---

Radio interferometry is amazing.  Nobel prize winning amazing since it turns the weak floppy photons of the radio spectrum into powerhouses of resolution.  However, there remains a sad fact of life that interferometers by themselves do not measure all the information in an image.  Specifically, interferometers measure Fourier components of the image. But they are poorly suited to actually measuring Fourier components with small wave numbers ($$||\mathbf{k}|| \sim 0$$).  These spatial frequencies are typically measured by single dish telescopes and then... somehow... stitched together into single images.  In theory, this is a well understood process, but there is a complication.  In addition to only measuring large wave numbers, interferometers also only measure certain parts of the Fourier plane and so we need to... somehow... interpolate a complex function into places where it is not measured.  

People gleefully point out fun facts like interferometers measure zero net flux by construction and that there are an infinite number of possible solutions for the deconvolution process.  However, radio astronomers can stare at poorly deconvolved images and think "that isn't right."  We have a great prior (more like a prejudice) on what the sky looks like and so we accept families of solutions consistent with our prejudice.  To manage that, we tend to like minimum information deconvolution.

I'm trying to deconvolve a radio image from the VLA.  The VLA is an utterly amazing instrument and it produces huge amounts of data.  The supported software for the deconvolution is called `CASA` and the deconvolution and imaging of the data is handled through the `clean` or the affectionately named `tclean` where the `t` means `test`.  The data I'm used are large and I have to produce large images (100 field mosaics, $$2500\times 2500$$ pixel images).  This means that running clean once, for a single frequency channel is a multi-hour affair where I conduct a slow ballet around the various pitfalls of `tclean` to discover how to produces beautiful images.  I'm writing now since I see some progress.

First, I was seeing tons of streaking in the brighest channels of the image.  At first, I worried these were RFI, but they showed up in every observation of the field.  It was something wrong with the imager.  I tried all kinds of stabilization tricks for `tclean` by restricting deconvolution to specific regions via a `mask` and feeding in `model` images which are an initial guess for what the true sky looks like before the effects of the interferometer are applied.  What ended up working was simple: I was using the default `natural` weighting, which turns out to be non-ideal for imaging wide areas with lots of structure since it makes the beam large and blends together emission.  Switching this to `briggs` weighting with `robust=0.5` calmed down the deconvolution significantly.

Here's the full clean call that seems to be non-terrible:

```
tclean(vis=flist,specmode='cube',imagename='NH3_11',
       start="23.693764GHz", nchan=10, restfreq="23.69450GHz",
       width='10.416kHz', imsize=[2500,2500],
       gridder='mosaic', restoringbeam='common',
       cell=['0.5arcsec'], pbcor=True, outframe='LSRK',
       niter=100000, chanchunks=-1,
       weighting='briggs', robust=0.5,
       deconvolver='multiscale', scales=[0,4,12,30],
       threshold='0.8mJy', mask='nh3_11_gas.mask', calcres=False,
       calcpsf=False, restart=True, 
       phasecenter='J2000 3h28m59.474s 31d16m11.85s')
```
